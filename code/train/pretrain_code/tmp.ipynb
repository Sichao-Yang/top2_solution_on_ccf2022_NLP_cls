{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f902e4b9-cc85-49d2-a5f9-fa4c5e225d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 01:00:49.371865: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-02 01:00:49.371901: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import jieba\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84978791-2bbb-4970-aae7-f090878cf03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint =  '/root/autodl-tmp/pretrained_models/bert_large_UER'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a56710d-d838-43b8-a17b-09dceb5bc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 1227927\n",
    "random.seed(seed_value) # Python\n",
    "np.random.seed(seed_value) # cpu vars\n",
    "# torch.manual_seed(seed_value) # cpu  vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83c085e-a77f-490b-8f54-1cc4a0fb58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/发明专利数据.json', 'r') as f:\n",
    "    train_data_patent = f.readlines()\n",
    "#     json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cebeb7-56f8-4126-a3e4-dc8e2af9565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/autodl-tmp/CCF-小样本/data/train.json', 'r')as f:\n",
    "    train_data = f.readlines()\n",
    "    train_data = [eval(i.strip())for i in train_data]\n",
    "    \n",
    "with open('/root/autodl-tmp/CCF-小样本/data/testA.json', 'r')as f:\n",
    "    test_data = f.readlines()\n",
    "    test_data = [eval(i.strip())for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1041c2c-afdf-4bb6-882a-0b714093fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = eval(str(train_data_patent))\n",
    "# dd = str()\n",
    "train_data_patent = str(train_data_patent)\n",
    "\n",
    "\n",
    "data = re.compile('{.*?}').findall(train_data_patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d02a2f-f09a-4e87-aa35-3bcb6e79b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281460/281460 [00:03<00:00, 77500.37it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_data = []\n",
    "train_data_ = []\n",
    "for i in tqdm(data):\n",
    "    tmp = dict()\n",
    "    pat_applicant = re.compile('\"pat_applicant\":\"(.*?)\",').findall(i)\n",
    "    pat_name = re.compile('\"pat_name\":\"(.*?)\",').findall(i)\n",
    "    pat_summary = re.compile('\"pat_summary\":\"(.*?)\",').findall(i)\n",
    "    \n",
    "    if pat_applicant:\n",
    "        tmp['assignee'] = pat_applicant[0]\n",
    "    else:\n",
    "        tmp['assignee'] = ''\n",
    "        \n",
    "        \n",
    "    if pat_name:\n",
    "        tmp['title'] = pat_name[0]\n",
    "        train_data_.append(pat_name[0])\n",
    "    else:\n",
    "        tmp['title'] = ''\n",
    "\n",
    "    if pat_summary:\n",
    "        tmp['abstract'] = pat_summary[0]\n",
    "        train_data_.append(pat_summary[0])\n",
    "    else:\n",
    "        tmp['abstract'] = ''\n",
    "    \n",
    "    clean_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96466c3-d6e1-46cc-858f-c81f5572b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'assignee': '重庆燃气集团股份有限公司',\n",
       "  'title': '一种燃气管封堵装置及封堵方法',\n",
       "  'abstract': '一种燃气管封堵装置，涉及燃气工程领域，其包括动力装置、弹性垫和压板；动力装置包括缸体、缸盖、活塞及活塞杆；缸体内设有腔室，缸体具备第一端面及第二端面，活塞杆包括第一端及第二端；活塞与活塞杆固定连接，并且活塞杆贯穿缸体；弹性垫设置在压板及第一端面之间。该装置结构简单使用方便，能够快速的与燃气管对接，并且通过动力装置能够与燃气管内壁紧密的贴合，封堵效果良好，能够有效防止泄漏。基于上述的燃气管封堵装置，本发明还提供了一种封堵方法。'},\n",
       " {'id': '538f267d2e6fba48b1286fb7f1499fe7',\n",
       "  'title': '一种信号的发送方法及基站、用户设备',\n",
       "  'assignee': '华为技术有限公司',\n",
       "  'abstract': '一种信号的发送方法及基站、用户设备。在一个子帧中为多个用户设备配置的参考信号的符号和数据的符号在子帧中的时域位置关系满足前提一和前提二；前提一为，将每个用户设备的参考信号所需的资源包括在多个参考信号的符号中，前提二为以下条件中的至少一个：将每个用户设备的多个参考信号设置在每个用户设备的数据的符号之前的参考信号的符号中，和/或每个用户设备的数据的符号之后的参考信号的符号中，从而有效地节省了发送参考信号的开销，满足了资源设计的需求；且部分或全部用户设备可在多个参考信号的符号中包含其参考信号，使该用户设备的解调性能得到进一步改善。',\n",
       "  'label_id': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[0], train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64140c4-74c3-411c-acd3-053ebbe94db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_titles = set()\n",
    "\n",
    "\n",
    "for i in train_data:\n",
    "    patent_titles.add(i['title'])\n",
    "    \n",
    "for i in test_data:\n",
    "    patent_titles.add(i['title'])\n",
    "    \n",
    "for i in clean_data:\n",
    "    patent_titles.add(i['title'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811f9dea-cb94-4682-99a3-0c8beaa99ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 303257/303257 [00:01<00:00, 221726.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrain_data = []\n",
    "\n",
    "cut_text_len = 506\n",
    "\n",
    "for i in tqdm(train_data + test_data + clean_data):\n",
    "    \n",
    "    if not i['title'] or not i['abstract']: continue\n",
    "    \n",
    "    title = i['title']\n",
    "    abstract = i['abstract']\n",
    "    assignee = i['assignee']\n",
    "    label = '1'\n",
    "    if random.random() > 10: ####################\n",
    "        sample_title = ''\n",
    "        while sample_title == title or sample_title: \n",
    "            sample_title = random.sample(patent_titles, 1)[0]\n",
    "        title = sample_title\n",
    "        label = '0'\n",
    "        \n",
    "\n",
    "        \n",
    "    title_len = len(title)\n",
    "    abstract_len = len(abstract)\n",
    "    assignee_len = len(assignee)\n",
    "    cut_text_len_ = cut_text_len - title_len - assignee_len\n",
    "    \n",
    "    \n",
    "    cut_count = math.ceil(abstract_len / cut_text_len_)\n",
    "    \n",
    "    for j in range(cut_count):\n",
    "        start = j * cut_text_len_\n",
    "        end = (j+1) * cut_text_len_\n",
    "        \n",
    "        sub_abstract = abstract[start: end]\n",
    "        \n",
    "        \n",
    "        if len(sub_abstract) > 10:\n",
    "            tmp = title + '---' + assignee + '---' + sub_abstract + '---' + label\n",
    "            pretrain_data.append(tmp)\n",
    "\n",
    "# for i in clean_data:\n",
    "#     title = i['pat_name']\n",
    "#     abstract = i['abstract']\n",
    "#     label = '1'    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fccc99c-12c6-490a-a60c-cb101e1fdd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(pretrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1852cdc-a563-4ccb-bbd4-d0f5268c7a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303486"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pretrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fccc80-f22b-43ca-b187-700132c0856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./abstracts_new.txt', 'w') as f:\n",
    "    f.write('\\n'.join(pretrain_data))\n",
    "    \n",
    "with open('./abstracts_new_test.txt', 'w') as f:\n",
    "    f.write('\\n'.join(pretrain_data[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7d668-aa2d-44f2-a6da-5f84d84ab97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76395it [03:16, 343.17it/s]"
     ]
    }
   ],
   "source": [
    "for idx, line in tqdm(enumerate(pretrain_data[:])):\n",
    "        words_ids = []\n",
    "        line = line.strip().split('---')\n",
    "        title = line[0]\n",
    "        assignee = line[1]\n",
    "        abstract = line[2]\n",
    "        label = line[3]\n",
    "\n",
    "        words_ids = []\n",
    "        tokens_title = tokenizer.tokenize(title)\n",
    "        tokens_assignee= tokenizer.tokenize(assignee)\n",
    "        tokens_abstract = tokenizer.tokenize(abstract)\n",
    "\n",
    "        tokens = [\"[CLS]\"] + tokens_title + [\"[SEP]\"] + tokens_assignee + [\"[SEP]\"] + tokens_abstract + [\"[SEP]\"]\n",
    "        \n",
    "        if len(tokens) >= 512:\n",
    "            print(idx, line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05bc510c-0707-4ced-a7c1-961ac3d3f7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f177806-8210-4b03-ae63-ae93ccbf04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9251da-ee04-48ef-9d93-c8be958c5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/patent_data.json', 'w') as f:\n",
    "    f.write('\\n'.join([str(i) for i in clean_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4043ec26-f2d9-44c8-942f-2fec44e3c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./abstracts.txt', 'r') as f:\n",
    "    train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b10fb12-34e4-4d10-8d6b-981fde54b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data + train_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acb6c9a-2bda-4b3b-995b-154ac053f382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 584490/584490 [00:01<00:00, 394075.57it/s]\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "cut_text_len = 510\n",
    "\n",
    "for content in tqdm(train_data):\n",
    "    content_len = len(content)\n",
    "    \n",
    "    new_content = []\n",
    "    cun_count = math.ceil(content_len / cut_text_len)\n",
    "    \n",
    "    for i in range(cun_count):\n",
    "        start = i * cut_text_len\n",
    "        end = (i+1) * cut_text_len\n",
    "        sub_content = content[start: end]\n",
    "        sub_content_len = len(sub_content)\n",
    "        mid_content_len = int(sub_content_len / 2)\n",
    "        new_data.append(sub_content)\n",
    "        \n",
    "#         if sub_content_len > 256 and random.random() > 0.9:\n",
    "#             cut_num = random.choice(range(mid_content_len, mid_content_len + random.choice(range(5, 20))))\n",
    "#             new_data.append(sub_content[: cut_num])\n",
    "#             new_data.append(sub_content[cut_num: ])\n",
    "\n",
    "#         else:\n",
    "#             new_data.append(sub_content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3139112d-1942-4143-9cc9-34dd297852ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/CCF-小样本/Nezha_pytorch/pretrain\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cd401e-3d6e-49c9-a5e0-e03ca1a54214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [i.strip() for i in new_data if i.strip()]\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7269db3-2597-429e-a9f2-be2ebe27f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./abstracts_new.txt', 'w') as f:\n",
    "    f.write('\\n'.join(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b76648-b9c1-4554-bb89-a677747dd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./abstracts_new_test.txt', 'w') as f:\n",
    "    f.write('\\n'.join(new_data[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb6e2fc-7422-4a52-98cd-6bcfdd4ba2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./abstracts_new_test.txt', 'r') as f:\n",
    "    abstracts_new_test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66321e36-4f5e-44f6-b0b6-2433eb2095cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一种信号的发送方法及基站、用户设备。在一个子帧中为多个用户设备配置的参考信号的符号和数据的符号在子帧中的时域位置关系满足前提一和前提二；前提一为，将每个用户设备的参考信号所需的资源包括在多个参考信号的符号中，前提二为以下条件中的至少一个：将每个用户设备的多个参考信号设置在每个用户设备的数据的符号之前的参考信号的符号中，和/或每个用户设备的数据的符号之后的参考信号的符号中，从而有效地节省了发送参考信号的开销，满足了资源设计的需求；且部分或全部用户设备可在多个参考信号的符号中包含其参考信号，使该用户设备的解调性能得到进一步改善。\\n',\n",
       " '本发明公开了一种5G通讯电缆故障监控系统，包括信号采样模块、补偿反馈模块，所述信号采样模块对5G通讯电缆信号采样，信号采样模块连接补偿反馈模块，补偿反馈模块运用三极管Q1、电容C3和电感L2、电容C2组成高频补偿电路展宽信号的通频带，为了进一步保证滤除扰动信号的准确性，避免异常高电平信号击穿电感L3，运用三极管Q4检测运放器AR2输出端信号，将异常高电平信号经电阻R14分压，最后运用运放器AR3同相放大信号，三极管Q5进一步三极管运放器AR3输出信号、三极管Q3发射极信号电位差，运用三极管Q2反馈信号至运放器AR2输出端，对运放器AR3输出信号峰值进一步校准，5G通讯电缆故障监控系统终端能够及时对5G通讯电缆故障及时响应。\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_new_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e137b96-757e-48cb-86ad-9af7b29aa21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一种信号的发送方法及基站、用户设备。在一个子帧中为多个用户设备配置的参考信号的符号和数据的符号在子帧中的时域位置关系满足前提一和前提二；前提一为，将每个用户设备的参考信号所需的资源包括在多个参考信号的符号中，前提二为以下条件中的至少一个：将每个用户设备的多个参考信号设\\n',\n",
       " '置在每个用户设备的数据的符号之前的参考信号的符号中，和/或每个用户设备的数据的符号之后的参考信号的符号中，从而有效地节省了发送参考信号的开销，满足了资源设计的需求；且部分或全部用户设备可在多个参考信号的符号中包含其参考信号，使该用户设备的解调性能得到进一步改善。\\n',\n",
       " '\\n',\n",
       " '本发明公开了一种5G通讯电缆故障监控系统，包括信号采样模块、补偿反馈模块，所述信号采样模块对5G通讯电缆信号采样，信号采样模块连接补偿反馈模块，补偿反馈模块运用三极管Q1、电容C3和电感L2、电容C2组成高频补偿电路展宽信号的通频带，为了进一步保证滤除扰动信号的准确性，避免异常高电平信号击穿电感L3，运用三极管Q4检测运放器AR2输出端信号，将异常高电平\\n',\n",
       " '信号经电阻R14分压，最后运用运放器AR3同相放大信号，三极管Q5进一步三极管运放器AR3输出信号、三极管Q3发射极信号电位差，运用三极管Q2反馈信号至运放器AR2输出端，对运放器AR3输出信号峰值进一步校准，5G通讯电缆故障监控系统终端能够及时对5G通讯电缆故障及时响应。\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d500d44-9174-4816-8d4d-92ccd7b1e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
